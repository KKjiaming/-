{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers import EarlyStoppingCallback\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n\nVER=2\n# TRAIN WITH SUBSET OF 60K\nNUM_TRAIN_SAMPLES = 60000\n# PARAMETER EFFICIENT FINE TUNING\n# PEFT REQUIRES 1XP100 GPU NOT 2XT4\nUSE_PEFT = False\n# NUMBER OF LAYERS TO FREEZE \n# DEBERTA LARGE HAS TOTAL OF 24 LAYERS\nFREEZE_LAYERS = 22\n# BOOLEAN TO FREEZE EMBEDDINGS\nFREEZE_EMBEDDINGS = True\n# LENGTH OF CONTEXT PLUS QUESTION ANSWER\nMAX_INPUT = 512\n# HUGGING FACE MODEL\nMODEL = 'microsoft/deberta-v3-large'","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:22.733322Z","iopub.execute_input":"2023-09-23T03:00:22.733582Z","iopub.status.idle":"2023-09-23T03:00:42.481792Z","shell.execute_reply.started":"2023-09-23T03:00:22.733556Z","shell.execute_reply":"2023-09-23T03:00:42.480777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid = pd.read_csv('/kaggle/input/60k-data-with-context-v2/train_with_context2.csv')\nprint('Validation data size:', df_valid.shape )\ndf_valid.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:42.483648Z","iopub.execute_input":"2023-09-23T03:00:42.483939Z","iopub.status.idle":"2023-09-23T03:00:42.541355Z","shell.execute_reply.started":"2023-09-23T03:00:42.483915Z","shell.execute_reply":"2023-09-23T03:00:42.540460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/60k-data-with-context-v2/all_12_with_context2.csv')\ndf_train = df_train.drop(columns=\"source\")\ndf_train = df_train.fillna('').sample(NUM_TRAIN_SAMPLES)\nprint('Train data size:', df_train.shape )\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:42.542941Z","iopub.execute_input":"2023-09-23T03:00:42.544429Z","iopub.status.idle":"2023-09-23T03:00:51.742703Z","shell.execute_reply.started":"2023-09-23T03:00:42.544391Z","shell.execute_reply":"2023-09-23T03:00:51.741469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.answer.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.746358Z","iopub.execute_input":"2023-09-23T03:00:51.747208Z","iopub.status.idle":"2023-09-23T03:00:51.767162Z","shell.execute_reply.started":"2023-09-23T03:00:51.747165Z","shell.execute_reply":"2023-09-23T03:00:51.765960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Sample 10,000 samples for each label\nsampled_data = []\n\nfor label in ['A', 'C', 'B', 'D', 'E']:\n    label_data = df_train[df_train['answer'] == label]\n    sampled_data.append(label_data.sample(n=6000, replace=True))\n\n# Create a new DataFrame with the sampled data\nbalanced_df = pd.concat(sampled_data)\n\n# Shuffle the rows to randomize the order\nbalanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\nbalanced_df.answer.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.769132Z","iopub.execute_input":"2023-09-23T03:00:51.769570Z","iopub.status.idle":"2023-09-23T03:00:51.877670Z","shell.execute_reply.started":"2023-09-23T03:00:51.769535Z","shell.execute_reply":"2023-09-23T03:00:51.876598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_data, validation_set = train_test_split(balanced_df, test_size=1000, stratify=balanced_df['answer'], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.879063Z","iopub.execute_input":"2023-09-23T03:00:51.879462Z","iopub.status.idle":"2023-09-23T03:00:51.947278Z","shell.execute_reply.started":"2023-09-23T03:00:51.879424Z","shell.execute_reply":"2023-09-23T03:00:51.946372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid = pd.concat([df_valid, validation_set], axis=0)\n\n# If you want to reset the index of the concatenated DataFrame\nvalid.reset_index(drop=True, inplace=True)\nvalid.drop_duplicates(subset='prompt', inplace=True)\nvalid.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.949325Z","iopub.execute_input":"2023-09-23T03:00:51.950021Z","iopub.status.idle":"2023-09-23T03:00:51.960657Z","shell.execute_reply.started":"2023-09-23T03:00:51.949988Z","shell.execute_reply":"2023-09-23T03:00:51.959588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_train_data = train_data[~train_data['prompt'].isin(valid['prompt'])]\nfiltered_train_data.drop_duplicates(subset='prompt', inplace=True)\nfiltered_train_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.962266Z","iopub.execute_input":"2023-09-23T03:00:51.962736Z","iopub.status.idle":"2023-09-23T03:00:51.994498Z","shell.execute_reply.started":"2023-09-23T03:00:51.962704Z","shell.execute_reply":"2023-09-23T03:00:51.993522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n                                  max_length=MAX_INPUT, add_special_tokens=False)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:51.995888Z","iopub.execute_input":"2023-09-23T03:00:51.996299Z","iopub.status.idle":"2023-09-23T03:00:52.010892Z","shell.execute_reply.started":"2023-09-23T03:00:51.996266Z","shell.execute_reply":"2023-09-23T03:00:52.009796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL)\ndataset_valid = Dataset.from_pandas(valid)\ndataset = Dataset.from_pandas(filtered_train_data)\ndataset = dataset.remove_columns([\"__index_level_0__\"])\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:52.015054Z","iopub.execute_input":"2023-09-23T03:00:52.015515Z","iopub.status.idle":"2023-09-23T03:00:54.906629Z","shell.execute_reply.started":"2023-09-23T03:00:52.015483Z","shell.execute_reply":"2023-09-23T03:00:54.905563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:00:54.908212Z","iopub.execute_input":"2023-09-23T03:00:54.908584Z","iopub.status.idle":"2023-09-23T03:12:33.065586Z","shell.execute_reply.started":"2023-09-23T03:00:54.908551Z","shell.execute_reply":"2023-09-23T03:12:33.064436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:12:33.067537Z","iopub.execute_input":"2023-09-23T03:12:33.067943Z","iopub.status.idle":"2023-09-23T03:12:42.001036Z","shell.execute_reply.started":"2023-09-23T03:12:33.067907Z","shell.execute_reply":"2023-09-23T03:12:42.000139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FREEZE_EMBEDDINGS:\n    print('Freezing embeddings.')\n    for param in model.deberta.embeddings.parameters():\n        param.requires_grad = False\nif FREEZE_LAYERS>0:\n    print(f'Freezing {FREEZE_LAYERS} layers.')\n    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n        for param in layer.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:12:42.002648Z","iopub.execute_input":"2023-09-23T03:12:42.003028Z","iopub.status.idle":"2023-09-23T03:12:42.011409Z","shell.execute_reply.started":"2023-09-23T03:12:42.002993Z","shell.execute_reply":"2023-09-23T03:12:42.010417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_at_3(predictions, labels):\n    map_sum = 0\n    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n    for x,y in zip(pred,labels):\n        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n        map_sum += np.sum(z)\n    return map_sum / len(predictions)\n\ndef compute_metrics(p):\n    predictions = p.predictions.tolist()\n    labels = p.label_ids.tolist()\n    return {\"map@3\": map_at_3(predictions, labels)}","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:12:42.012827Z","iopub.execute_input":"2023-09-23T03:12:42.013858Z","iopub.status.idle":"2023-09-23T03:12:42.108747Z","shell.execute_reply.started":"2023-09-23T03:12:42.013819Z","shell.execute_reply":"2023-09-23T03:12:42.107629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    warmup_ratio=0.1, \n    learning_rate=6e-6,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=2,\n    num_train_epochs=1,\n    report_to='none',\n    output_dir = f'./checkpoints_{VER}',\n    overwrite_output_dir=True,\n    fp16=True,\n#     gradient_accumulation_steps=8,\n    logging_steps=250,\n    evaluation_strategy='steps',\n    eval_steps=250,\n    save_strategy=\"steps\",\n    save_steps=250,\n    load_best_model_at_end=True,\n    metric_for_best_model='map@3',\n    lr_scheduler_type='cosine',\n    weight_decay=0.01,\n    save_total_limit=2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:12:42.111411Z","iopub.execute_input":"2023-09-23T03:12:42.112748Z","iopub.status.idle":"2023-09-23T03:12:42.201578Z","shell.execute_reply.started":"2023-09-23T03:12:42.112715Z","shell.execute_reply":"2023-09-23T03:12:42.200653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset_valid,\n    compute_metrics = compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n)\n\ntrainer.train()\ntrainer.save_model(f'model_v{VER}')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T03:12:42.203060Z","iopub.execute_input":"2023-09-23T03:12:42.203397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}